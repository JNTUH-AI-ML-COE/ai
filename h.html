<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI-Powered Modern Software Development | Course Details</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
     * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --primary: #1e3a5f;
            --secondary: #2c5f8d;
            --accent: #3a7ca5;
            --light: #81b7d2;
            --bg-main: #f8f9fa;
            --bg-card: #ffffff;
            --text-primary: #1a1a1a;
            --text-secondary: #4a5568;
            --text-muted: #6b7280;
            --border-light: #e5e7eb;
            --border-accent: #d1d5db;
            --success: #10b981;
            --warning: #f59e0b;
            --shadow-sm: 0 1px 2px rgba(0, 0, 0, 0.05);
            --shadow-md: 0 4px 6px rgba(0, 0, 0, 0.07);
            --shadow-lg: 0 10px 20px rgba(0, 0, 0, 0.1);
            --shadow-xl: 0 20px 40px rgba(0, 0, 0, 0.12);
            --transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            --transition-fast: all 0.15s ease;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif;
            background: var(--bg-main);
            color: var(--text-primary);
            line-height: 1.6;
            overflow-x: hidden;
        }

        header {
            background: linear-gradient(135deg, var(--primary) 0%, var(--secondary) 50%, var(--accent) 100%);
            color: white;
            text-align: center;
            padding: 4rem 2rem 3rem;
            position: relative;
            overflow: hidden;
            box-shadow: var(--shadow-xl);
        }

        header::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(255,255,255,0.1) 1px, transparent 1px);
            background-size: 50px 50px;
            animation: movePattern 30s linear infinite;
            opacity: 0.3;
        }

        @keyframes movePattern {
            0% { transform: translate(0, 0); }
            100% { transform: translate(50px, 50px); }
        }

        header h1 {
            font-size: clamp(2rem, 5vw, 3rem);
            font-weight: 800;
            letter-spacing: -0.02em;
            margin-bottom: 0.75rem;
            position: relative;
            z-index: 1;
            animation: fadeInDown 0.8s ease;
        }

        @keyframes fadeInDown {
            from {
                opacity: 0;
                transform: translateY(-30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        header p {
            font-size: clamp(1.1rem, 2.5vw, 1.4rem);
            opacity: 0.95;
            position: relative;
            z-index: 1;
            font-weight: 300;
            animation: fadeInUp 0.8s ease 0.2s backwards;
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        nav {
            background: var(--bg-card);
            box-shadow: var(--shadow-md);
            position: sticky;
            top: 0;
            z-index: 1000;
            padding: 1rem;
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            align-items: center;
            gap: 0.75rem;
            transition: var(--transition);
            backdrop-filter: blur(10px);
        }

        nav.scrolled {
            box-shadow: var(--shadow-lg);
            background: rgba(255, 255, 255, 0.95);
        }

        nav a {
            color: var(--text-secondary);
            background: var(--bg-main);
            text-decoration: none;
            font-weight: 600;
            padding: 0.7rem 1.4rem;
            border-radius: 10px;
            font-size: 0.95rem;
            transition: var(--transition);
            border: 2px solid transparent;
            position: relative;
            overflow: hidden;
        }

        nav a::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            width: 0;
            height: 0;
            border-radius: 50%;
            background: var(--accent);
            transition: width 0.4s ease, height 0.4s ease;
            transform: translate(-50%, -50%);
            z-index: -1;
        }

        nav a:hover::before {
            width: 300px;
            height: 300px;
        }

        nav a:hover {
            color: white;
            border-color: var(--accent);
            transform: translateY(-2px);
            box-shadow: var(--shadow-md);
        }

        main {
            max-width: 1200px;
            margin: 3rem auto;
            background: var(--bg-card);
            padding: 3rem;
            border-radius: 20px;
            box-shadow: var(--shadow-lg);
            animation: fadeIn 0.8s ease;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: scale(0.98); }
            to { opacity: 1; transform: scale(1); }
        }

        section {
            margin-bottom: 3rem;
        }

        h2 {
            font-size: clamp(1.75rem, 4vw, 2.5rem);
            font-weight: 700;
            color: var(--primary);
            margin-bottom: 1.5rem;
            padding-bottom: 1rem;
            border-bottom: 3px solid var(--accent);
            position: relative;
            transition: var(--transition);
        }

        h2::after {
            content: '';
            position: absolute;
            bottom: -3px;
            left: 0;
            width: 100px;
            height: 3px;
            background: var(--success);
            transition: width 0.4s ease;
        }

        section:hover h2::after {
            width: 150px;
        }

        h3 {
            font-size: clamp(1.3rem, 3vw, 1.6rem);
            font-weight: 600;
            color: var(--secondary);
            margin: 2rem 0 1.5rem;
        }

        section > p {
            line-height: 1.8;
            color: var(--text-secondary);
            margin-bottom: 1.5rem;
            font-size: 1.05rem;
        }

        section > ul {
            list-style: none;
            padding-left: 0;
            margin-bottom: 1.5rem;
        }

        section > ul li {
            padding-left: 2rem;
            margin-bottom: 1rem;
            position: relative;
            line-height: 1.75;
            color: var(--text-secondary);
            transition: var(--transition-fast);
        }

        section > ul li::before {
            content: 'â†’';
            position: absolute;
            left: 0;
            color: var(--accent);
            font-weight: bold;
            font-size: 1.3rem;
            transition: var(--transition-fast);
        }

        section > ul li:hover {
            color: var(--primary);
            transform: translateX(5px);
        }

        section > ul li:hover::before {
            color: var(--success);
            transform: scale(1.2);
        }
    /* Highlighted Key Info/References/Important */
    .key, .important, .references, .prereq, .sources {
      background: var(--highlight);
      border-left: 6px solid var(--emphasis);
      padding: 1.2em 1em 1.2em 1.3em;
      border-radius: 7px;
      font-size: 1.05em;
      margin-bottom: 1.5em;
      transition: all 0.3s ease;
    }
    .key:hover, .important:hover, .references:hover, .prereq:hover, .sources:hover {
      box-shadow: 0 4px 16px rgba(44,152,99, 0.12);
      background: #e9f4fb;
      transform: translateX(4px);
    }

    /* Week section */
    .week {
      transition: all 0.3s ease;
    }

    /* Unique badge for titles */
    .domain-head, .week-title {
      background: var(--accent);
      color: #fff;
      font-size: 1.09em;
      font-weight: 600;
      border-radius: 7px;
      padding: 0.7em 1.1em;
      display: inline-block;
      margin-bottom: .9em;
      margin-top: 1.2em;
      transition: all 0.3s ease;
    }
    .domain-head:hover, .week-title:hover {
      background: var(--primary);
      transform: translateX(6px);
      box-shadow: 0 4px 12px rgba(23,74,124,0.2);
    }

    /* Timeline Steps (horizontal, scrollable) */
    .timeline {
      margin: 24px 0 40px 0;
      display: flex;
      overflow-x: auto;
      gap: 14px;
      scrollbar-color: var(--accent) #f3f8fe;
      scrollbar-width: thin;
    }
    .timeline-step {
      flex: 0 0 175px;
      background: var(--highlight);
      border: 2px solid var(--accent);
      border-radius: 13px;
      padding: 16px 8px;
      text-align: center;
      font-weight: 600;
      font-size: .96em;
      box-shadow: 0 1px 3px 0 rgba(87,162,230,.06);
      transition: all 0.3s ease;
      cursor: pointer;
    }
    .timeline-step:hover {
      background: #dbefff;
      border-color: var(--danger);
      box-shadow: 0 6px 20px 0 rgba(87,162,230,.15);
      color: var(--primary);
      transform: translateY(-4px) scale(1.05);
    }

    ul {
      margin-bottom: 1em;
      margin-left: 24px;
    }

    /* Objectives and inline item hover */
    .objectives li, ul li {
      transition: all 0.3s ease;
    }
    .objectives li:hover, ul li:hover {
      color: var(--emphasis);
      transform: translateX(4px);
    }

    a, .ref-link {
      color: var(--accent);
      text-underline-offset: 2px;
      transition: all 0.3s ease;
      position: relative;
    }
    a:hover, .ref-link:hover {
      color: var(--danger);
      transform: translateX(2px);
    }

    details {
      margin-bottom: 14px;
      transition: all 0.3s ease;
      border: 1px solid transparent;
      border-radius: 8px;
      padding: 8px;
    }
    details:hover {
      background: #f9fcff;
      border-color: var(--accent);
      box-shadow: 0 2px 8px rgba(87,162,230,0.1);
    }
    summary {
      font-weight: 600;
      cursor: pointer;
      outline: none;
      transition: all 0.3s ease;
      padding: 8px;
      border-radius: 4px;
    }
    summary:hover {
      color: var(--primary);
      background-color: #e8f1ff;
      transform: translateX(4px);
    }
    details[open] summary {
      color: var(--primary);
      background-color: #e8f1ff;
    }

    /* Reference list items */
    .ref-list li {
      transition: all 0.3s ease;
      padding: 4px 0;
    }
    .ref-list li:hover {
      padding-left: 8px;
    }

    /* Responsive Design Tweaks */
    @media (max-width: 900px) {
      main { padding: 1.2em 0.7em; }
      .timeline-step { flex-basis: 125px; font-size: .93em; }
    }
    @media (max-width: 700px) {
      main { padding: 1.1em 0.2em; }
      .timeline-step { flex-basis: 90px; font-size: .84em; padding: 9px 3px; }
      .domain-head, .week-title { font-size: 1em; padding: .5em .7em; }
    }
    @media (max-width: 480px) {
      body { font-size: .95em; }
      .key, .important, .references, .sources, .prereq { padding: 0.7em 0.55em 0.7em 0.7em; }
      .week, .timeline-step { padding: 9px 2px;}
      nav a { font-size: 0.97em; padding: 0.4rem 0.7rem;}
    }
  </style>
</head>
<body>
  <header>
    <h1>Advanced Domain-Specific Applied AI</h1>
    <p>Graduate Syllabus &nbsp;Â·&nbsp; 2025</p>
  </header>
  <nav>
    <a href="#overview">Overview</a>
    <a href="#objectives">Objectives</a>
    <a href="#prerequisites">Prerequisites</a>
    <a href="#structure">Structure</a>
    <a href="#timeline">Timeline</a>
    <a href="#semester1">Semester 1</a>
    <a href="#semester2">Semester 2</a>
    <a href="#readings">Readings</a>
  </nav>
  <main>
    <section class="key" id="overview">
      <strong><h2>Course Overview:</h2></strong>
      This graduate sequence explores advanced techniques for developing AI tailored to multiple industriesâ€”healthcare, finance, legal, retail, and more. Students learn to specialize and adapt deep learning and foundation models for application in real-world, high-impact settings, with strong focus on hands-on implementation, using state-of-the-art methods like transfer learning, knowledge distillation, synthetic data generation, and efficient fine-tuning.
    </section>

    <section id="objectives">
      <h2>Learning Objectives</h2>
      <ul>
        <li>Specialize and adapt pre-trained AI models to various domains using advanced transfer learning and domain adaptation techniques.</li>
        <li>Implement model compression, knowledge distillation, and efficient deployment.</li>
        <li>Create and evaluate synthetic data for domains with limited/sensitive datasets.</li>
        <li>Develop domain-specific solutions for at least 4â€“7 verticals, demonstrating awareness of unique requirements and ethics in each field.</li>
        <li>Translate recent research to practical implementations (projects, assignments).</li>
      </ul>
    </section>
    
    <section id="prerequisites" class="prereq">
      <h3>Prerequisites</h3>
      <ul>
        <li>Strong background in ML/deep learning (coursework or equivalent experience)</li>
        <li>Solid Python, PyTorch/TensorFlow skills</li>
        <li>Basic AI ethics and privacy understanding suggested</li>
      </ul>
    </section>
    
    <section id="structure">
      <h2>Course Structure</h2>
      <ul>
        <li><b>Two Semesters</b> (Fall 2025 + Spring 2026) Â· 12â€“13 weeks instruction per semester</li>
        <li><b>Semester 1:</b> Core methods & foundational domains, practical mini-projects each module</li>
        <li><b>Semester 2:</b> Advanced topics, extra domains, major capstone project in chosen vertical</li>
        <li>Weekly lectures, paper discussions, hands-on labs, guest speakers from industry/academia</li>
        <li>Frequent problem sets, project checkpoints, final capstone project</li>
      </ul>
    </section>

    <section id="timeline">
      <h2>Course Timeline</h2>
      <div class="timeline">
        <div class="timeline-step">Intro & Domains</div>
        <div class="timeline-step">Transfer & Adaptation</div>
        <div class="timeline-step">Distillation</div>
        <div class="timeline-step">Synthetic Data</div>
        <div class="timeline-step">Healthcare AI</div>
        <div class="timeline-step">Finance AI</div>
        <div class="timeline-step">Legal AI</div>
        <div class="timeline-step">Adv. Fine-Tuning</div>
        <div class="timeline-step">Multi-Modal</div>
        <div class="timeline-step">Retail/E-commerce</div>
        <div class="timeline-step">Capstone</div>
      </div>
    </section>
        <section id="semester1">
  <h2>Semester 1: Foundations of Domain-Specific AI (Fall 2025)</h2>
  <div class="domain-head">Weeks 1â€“2: Introduction to Domain-Specific AI</div>
  <ul>
    <li>
      <strong>Overview:</strong> Why AI must be adapted for specific domains. Typical shortcomings of generic models (e.g. general NLP vs. medical/legal NLP). High-stakes errors and data scarcity.
    </li>
    <li>
      <strong>Case Studies:</strong>
      <ul>
        <li>BloombergGPT: 50B param finance LLM, trained on domain-specific corpora, dramatically outperforms general models on finance tasks <a href="https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/" target="_blank">[BloombergGPT]</a>.</li>
        <li>Med-PaLM 2: Aligning LLMs to medicine, achieves >85% expert performance on USMLE-style questions <a href="https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model" target="_blank">[Med-PaLM 2]</a>.</li>
      </ul>
    </li>
    <li>
      <strong>Discussion/Lab:</strong>
      <ul>
        <li>Domain challenges: regulatory burdens, explainability, bias/fairness, updates for domain shifts.</li>
        <li>Team formation around multiple domains for semester projects.</li>
      </ul>
    </li>
  </ul>

  <div class="domain-head">Weeks 3â€“4: Transfer Learning and Domain Adaptation</div>
  <ul>
    <li>
      <strong>Objectives:</strong> Deep dive into transfer learning to adapt LLMs for new domains. Understand fine-tuning, continued pre-training, feature alignment, adversarial domain adaptation, multi-task learning.
    </li>
    <li>
      <strong>Techniques:</strong>
      <ul>
        <li>Parameter-Efficient Fine-Tuning (PEFT): Only update a small subset of the modelâ€”LoRA, adapters, QLoRA <a href="https://medium.com/@akankshasinha247/peft-lora-qlora-smarter-faster-fine-tuning-for-domain-llms-3d7b7fdf9671" target="_blank">[PEFT, LoRA]</a>.</li>
        <li>Feature alignment, domain-adversarial adaptation (esp. in vision).</li>
      </ul>
    </li>
    <li>
      <strong>Lab:</strong> Students fine-tune or adapt a base model for a chosen domain, comparing full vs. parameter-efficient adaptation.
    </li>
  </ul>

  <div class="domain-head">Weeks 5â€“6: Knowledge Distillation & Teacher/Professor Models</div>
  <ul>
    <li>
      <strong>Content:</strong> Learn to compress large models for deployment via distillation. Study teacher-student (classic) and professor-teacher-student (QUILL) multi-stage approaches <a href="https://dejan.ai/blog/query-intent-via-retrieval-augmentation-and-model-distillation/" target="_blank">[QUILL]</a>.
    </li>
    <li>
      <strong>Applications:</strong> Edge deployment (hospital devices, low-latency trading), ensemble and self-distillation.
    </li>
    <li>
      <strong>Lab:</strong> Distill a teacher into a student model using domain data. Evaluate efficiency and accuracy.
    </li>
    <li>
      <strong>Reference:</strong> <a href="https://www.amazon.science/publications/knowledge-distillation-with-training-wheels" target="_blank">Knowledge Distillation with Training Wheels</a>.
    </li>
  </ul>

  <div class="domain-head">Weeks 7â€“8: Synthetic Data Generation & Data Augmentation</div>
  <ul>
    <li>
      <strong>Motivation:</strong> How generative AI (GANs, VAEs, Diffusion, LLMs) can fill gaps with high-quality synthetic medical, legal, or financial data.
    </li>
    <li>
      <strong>Case Study:</strong> RoentGen, Stanfordâ€™s text-to-image X-ray generator â€” creates lifelike images for rare conditions, supports privacy <a href="https://stanmed.stanford.edu/generative-ai-synthetic-data-promise/" target="_blank">[Stanford Synthetic Data]</a>.
    </li>
    <li>
      <strong>Lab:</strong> Build and benchmark a model using real + synthetic data augmentation; discuss risks and validation.
    </li>
  </ul>

  <div class="domain-head">Weeks 9â€“10: Domain Focus â€“ AI in Healthcare</div>
  <ul>
    <li>
      <strong>Applications:</strong> Diagnostic imaging, EHR analytics, medical Q&A with LLMs. Emphasis on interpretability, federated learning, bias mitigation, regulatory constraints.
    </li>
    <li>
      <strong>Case:</strong> Use real datasets to build models (e.g., radiology classification, patient outcome prediction). Explore Med-PaLM 2, BioGPT, and federated learning.
    </li>
    <li>
      <strong>Lab:</strong> Adapt models for a healthcare task and analyze fairness metrics. Guest speaker discusses practical deployment.
    </li>
    <li>
      <strong>Reading:</strong> <a href="https://mlhcmit.github.io/" target="_blank">Machine Learning for Health MIT</a>.
    </li>
  </ul>

  <div class="domain-head">Weeks 11â€“12: Domain Focus â€“ AI in Finance</div>
  <ul>
    <li>
      <strong>Topics:</strong> NLP for finance (sentiment analysis, credit scoring), time-series modeling for trading/forecasting, fraud detection.
    </li>
    <li>
      <strong>Customization:</strong> BloombergGPT, FinBERT, continual/adaptive learning. Discuss bias, explainability, regulatory risks.
    </li>
    <li>
      <strong>Lab:</strong> Work with financial dataâ€”stock prices/news, and model for prediction/classification using domain customization.
    </li>
    <li>
      <strong>Reference:</strong> <a href="https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/" target="_blank">BloombergGPT overview</a>.
    </li>
  </ul>

  <div class="domain-head">Week 13: Domain Focus â€“ AI in Legal</div>
  <ul>
    <li>
      <strong>Applications:</strong> eDiscovery, contract review, legal research Q&A, drafting. LLMs for law (GPT-4 bar exam performance) <a href="https://openai.com/index/gpt-4-research/" target="_blank">[GPT-4 Research]</a>.
    </li>
    <li>
      <strong>Challenges:</strong> Verification, avoidance of hallucinations, use of RAG, bias, and legal ethics in AI.
    </li>
    <li>
      <strong>Lab:</strong> Evaluate output from legal AI systems vs. human analysis; propose capstone project ideas.
    </li>
  </ul>
</section>


<section id="semester2">
  <h2>Semester 2: Advanced Topics and Capstone (Spring 2026)</h2>
  <div class="domain-head">Weeks 1â€“2: Advanced Fine-Tuning & Adaptation</div>
  <ul>
    <li>
      <strong>Objectives:</strong> Master RLHF and instruction tuning for specific domains (aligning models with expert feedback), support continual/multi-domain learning and parameter isolation.
    </li>
    <li>
      <strong>Lab:</strong> Practice with open-source adapter tools, rapidly fine-tune and test foundation models in chosen domains.
    </li>
  </ul>

  <div class="domain-head">Weeks 3â€“4: Multi-Modal & Knowledge-Integrated Domain AI</div>
  <ul>
    <li>
      <strong>Multi-Modal Fusion:</strong> Combine vision, text, and signals for complex reasoning in healthcare, retail, or manufacturing.
    </li>
    <li>
      <strong>Knowledge Integration:</strong> Use ontologies, knowledge graphs, and symbolic rules to power reasoning and compliance-checking.
    </li>
    <li>
      <strong>Lab:</strong> Build a multi-modal or knowledge-integrated model for a class project.
    </li>
  </ul>

  <div class="domain-head">Week 5: Domain Focus â€“ AI in Retail & E-commerce</div>
  <ul>
    <li>
      <strong>Applications:</strong> Personalized recommendation, demand forecasting, chatbots, visual search, dynamic content generation.
    </li>
    <li>
      <strong>Case Study:</strong> Conversational commerce, Amazon Bedrock, hyper-personalization <a href="https://aws.amazon.com/blogs/industries/how-generative-ai-and-data-are-redefining-retail-experiences/" target="_blank">[AWS Retail AI]</a>.
    </li>
    <li>
      <strong>Lab:</strong> Prototype and measure improvements from domain-specific recsys/channel bots.
    </li>
  </ul>

  <div class="domain-head">Week 6: Domain Focus â€“ Manufacturing & Industry</div>
  <ul>
    <li>
      <strong>Apps:</strong> Predictive maintenance, robotics, quality control. Work with sensor data, edge deployment, sim-to-real transfer.
    </li>
    <li>
      <strong>Lab:</strong> Model equipment failures or forecast operations on manufacturing datasets.
    </li>
  </ul>

  <div class="domain-head">Week 7: Domain Focus â€“ AI in Education</div>
  <ul>
    <li>
      <strong>Topics:</strong> Intelligent tutors, grading, student progress, personalized feedback, ethics/fairness.
    </li>
    <li>
      <strong>Lab:</strong> Build and validate an educational chatbot or auto-grader; test for learning outcomes.
    </li>
  </ul>

  <div class="domain-head">Weeks 8â€“10: Capstone Project Development</div>
  <ul>
    <li>
      Design, implement, and evaluate domain-specific AI projects. Weekly progress reviews and just-in-time lectures for knowledge gaps.
    </li>
    <li>
      Milestones at Weeks 8, 9 for results and troubleshooting.
    </li>
  </ul>

  <div class="domain-head">Weeks 11â€“12: Final Presentations & Synthesis</div>
  <ul>
    <li>
      Present projects, compare strengths and weaknesses across domains, discuss generalization vs. customization.
    </li>
    <li>
      Reflect on lessons learned, future outlook, and responsible deployment.
    </li>
  </ul>
</section>

    
    <section id="readings">
  <h2>Recommended Readings & Key Research</h2>
  <ul>
    <li>
      <strong>Query Intent Classification, RAG & Distillation:</strong>
      <br>
      <a href="https://dejan.ai/blog/query-intent-via-retrieval-augmentation-and-model-distillation/" target="_blank">
        QUILL: Query Intent with Large Language Models using Retrieval Augmentation and Multi-stage Distillation
      </a>
      â€“ DEJAN  
      <ul>
        <li>
          <a href="https://dejan.ai/blog/query-intent-via-retrieval-augmentation-and-model-distillation/#:~:text=Two" target="_blank">Professor-Teacher-Student multi-stage distillation</a>
        </li>
        <li>
          <a href="https://dejan.ai/blog/query-intent-via-retrieval-augmentation-and-model-distillation/#:~:text=Second%20Stage%3A%20The%20Teacher%20model,than%20the%20Professor%20or%20Teacher" target="_blank">Teacher model distillation details</a>
        </li>
        <li>
          <a href="https://dejan.ai/blog/query-intent-via-retrieval-augmentation-and-model-distillation/#:~:text=using%20a%20larger%20dataset,than%20the%20Professor%20or%20Teacher" target="_blank">Student model efficiency</a>
        </li>
      </ul>
    </li>
    <li>
      <strong>Synthetic Data in Healthcare & Biomedicine:</strong>
      <br>
      <a href="https://stanmed.stanford.edu/generative-ai-synthetic-data-promise/" target="_blank">
        AI steps into the looking glass with synthetic data â€“ Stanford Medicine Magazine
      </a>
      <ul>
        <li>
          <a href="https://stanmed.stanford.edu/generative-ai-synthetic-data-promise/#:~:text=Leaders%20of%20this%20emerging%20field,all%20in%20a%20single%20stroke" target="_blank">Synthetic data promise</a>
        </li>
        <li>
          <a href="https://stanmed.stanford.edu/generative-ai-synthetic-data-promise/#:~:text=biomedical%20data%20science%2C%20Chaudhari%2C%20assistant,August%20in%20Nature%20Biomedical%20Engineering" target="_blank">Biomedical engineering applications</a>
        </li>
        <li>
          <a href="https://stanmed.stanford.edu/generative-ai-synthetic-data-promise/#:~:text=everyday%20work,trained%20eyes%20of%20medical%20professionals" target="_blank">Medical professional impact</a>
        </li>
        <li>
          <a href="https://stanmed.stanford.edu/generative-ai-synthetic-data-promise/#:~:text=Data%20from%20scratch" target="_blank">Data from scratch examples</a>
        </li>
        <li>
          <a href="https://stanmed.stanford.edu/generative-ai-synthetic-data-promise/#:~:text=While%20RoentGen%20is%20impressive%20in,help%20circumvent%20patient%20privacy%20concerns" target="_blank">RoentGen and privacy</a>
        </li>
        <li>
          <a href="https://stanmed.stanford.edu/generative-ai-synthetic-data-promise/#:~:text=Yet%20many%20leaders%20also%20urge,implications%20of%20this%20new%20field" target="_blank">Ethical concerns</a>
        </li>
      </ul>
    </li>
    <li>
      <strong>Fine-Tuning Domain LLMs (PEFT, LoRA, QLoRA):</strong>
      <br>
      <a href="https://medium.com/@akankshasinha247/peft-lora-qlora-smarter-faster-fine-tuning-for-domain-llms-3d7b7fdf9671" target="_blank">
        PEFT, LoRA & QLoRA: Smarter, Faster Fine-Tuning for Domain LLMs â€“ Akanksha Sinha (Medium)
      </a>
      <ul>
        <li>
          <a href="https://medium.com/@akankshasinha247/peft-lora-qlora-smarter-faster-fine-tuning-for-domain-llms-3d7b7fdf9671#:~:text=Fine,training%20on%20a%20curated%20dataset" target="_blank">Fine-tuning process</a>
        </li>
        <li>
          <a href="https://medium.com/@akankshasinha247/peft-lora-qlora-smarter-faster-fine-tuning-for-domain-llms-3d7b7fdf9671#:~:text=%E2%98%BC%20What%20is%20PEFT%3F" target="_blank">What is PEFT?</a>
        </li>
        <li>
          <a href="https://medium.com/@akankshasinha247/peft-lora-qlora-smarter-faster-fine-tuning-for-domain-llms-3d7b7fdf9671#:~:text=%E2%80%A2%20Risky" target="_blank">Risks and limitations</a>
        </li>
        <li>
          <a href="https://medium.com/@akankshasinha247/peft-lora-qlora-smarter-faster-fine-tuning-for-domain-llms-3d7b7fdf9671#:~:text=Meta%E2%80%99s%20fine,tune%20%E2%80%94%20options%20include" target="_blank">Meta's implementation</a>
        </li>
      </ul>
    </li>
    <li>
      <strong>Model Compression & Knowledge Distillation:</strong>
      <br>
      <a href="https://www.amazon.science/publications/knowledge-distillation-with-training-wheels" target="_blank">
        Knowledge distillation with training wheels â€“ Amazon Science
      </a>
    </li>
    <li>
      <strong>Deep Learning Course & Tutorials:</strong>
      <br>
      <a href="https://phillipi.github.io/6.7960/" target="_blank">
        6.7960 Deep Learning, Fall 2024 (Sara Beery, MIT)
      </a>
    </li>
    <li>
      <strong>Domain Case Studies:</strong>
      <ul>
        <li>
          <a href="https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/" target="_blank">
            BloombergGPT, Purpose-built 50B parameter LLM for Finance â€“ Bloomberg [performance, applications]
          </a>
        </li>
        <li>
          <a href="https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model" target="_blank">
            Med-PaLM 2 Medical LLM â€“ Google Cloud Blog
          </a>
        </li>
          <li>
          <a href="https://mlhcmit.github.io/" target="_blank">
            Machine Learning for Healthcare â€“ MLHC MIT
          </a>
        </li>
        <li>
          <a href="https://openai.com/index/gpt-4-research/" target="_blank">
            GPT-4 Research â€“ OpenAI
          </a>
        </li>
      </ul>
    </li>
    <li>
      <strong>Generative AI in Retail:</strong>
      <br>
      <a href="https://aws.amazon.com/blogs/industries/how-generative-ai-and-data-are-redefining-retail-experiences/" target="_blank">
        How generative AI and data are redefining retail experiences â€“ AWS for Industries
      </a>
      <ul>
        <li>
          <a href="https://aws.amazon.com/blogs/industries/how-generative-ai-and-data-are-redefining-retail-experiences/#:~:text=Take%20The%20Very%20Group%20,the%20quality%20of%20product%20descriptions" target="_blank">Generative product content</a>
        </li>
        <li>
          <a href="https://aws.amazon.com/blogs/industries/how-generative-ai-and-data-are-redefining-retail-experiences/#:~:text=product%20recommendations%2C%20dynamic%20content%20generation%2C,from%205%20to%2025%20percent" target="_blank">Product recommendations, dynamic content</a>
        </li>
        <li>
          <a href="https://aws.amazon.com/blogs/industries/how-generative-ai-and-data-are-redefining-retail-experiences/#:~:text=These%20innovations%20reflect%20a%20trend,Consumers%20are%20already" target="_blank">Industry impact/trends</a>
        </li>
      </ul>
    </li>
  </ul>
</section>

  </main>
</body>
</html>
